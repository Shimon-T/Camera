import UIKit
import AVFoundation
import Photos
import Observation
import Combine
import Vision

@MainActor
@Observable
class CameraManager: NSObject, ObservableObject {
    private var gestureFailureCount: Int = 0
    private let maxGestureFailures: Int = 3
    enum TimerPurpose {
        case gestureHold
        case captureDelay
    }
    
    let objectWillChange = ObservableObjectPublisher()
    public var showTimer: Bool = false
    public var isRecording: Bool = false
    public var timerCount: Int = 0
    public var timerTotal: Int = 0
    public var recordingDuration: Int = 0
    public var timerPurpose: TimerPurpose? = nil
    public var testNumber = 0
    private var recordingTimer: Timer?
    private var isDetecting: Bool = false
    private var gestureLock: Bool = false
    private var gestureStartTime: Date?
    private var currentGesture: String?
    let session = AVCaptureSession()
    private let sessionQueue = DispatchQueue(label: "session queue")
    private var videoDeviceInput: AVCaptureDeviceInput!
    private let photoOutput = AVCapturePhotoOutput()
    private let movieOutput = AVCaptureMovieFileOutput()
    private let handPoseRequest = VNDetectHumanHandPoseRequest()
    private let videoOutput = AVCaptureVideoDataOutput()
    
    override init() {
        super.init()
        configureSession()
    }
    
    private func configureSession() {
        session.beginConfiguration()
        
        // Add video input
        guard let videoDevice = AVCaptureDevice.default(.builtInWideAngleCamera, for: .video, position: .back),
              let videoDeviceInput = try? AVCaptureDeviceInput(device: videoDevice),
              session.canAddInput(videoDeviceInput) else {
            session.commitConfiguration()
            return
        }
        session.addInput(videoDeviceInput)
        self.videoDeviceInput = videoDeviceInput
        
        // Add photo output
        if session.canAddOutput(photoOutput) {
            session.addOutput(photoOutput)
        }
        
        // Add movie output
        if session.canAddOutput(movieOutput) {
            session.addOutput(movieOutput)
        }

        // Add video output for gesture detection
        if session.canAddOutput(videoOutput) {
            session.addOutput(videoOutput)
            videoOutput.setSampleBufferDelegate(self, queue: sessionQueue)
        }
        
        session.commitConfiguration()
    }
    
    func startRecording(after delay: TimeInterval) {
        DispatchQueue.main.async {
            self.isRecording = true
            self.recordingDuration = 0
            self.recordingTimer?.invalidate()
            self.recordingTimer = Timer.scheduledTimer(withTimeInterval: 1.0, repeats: true) { [weak self] _ in
                DispatchQueue.main.async {
                    self?.recordingDuration += 1
                }
            }
            self.startRecordingVideo()
        }
    }
    
    func switchCamera() {
        // TODO: Implement camera switching
    }
    
    private func startRecordingVideo() {
        let formatter = DateFormatter()
        formatter.dateFormat = "yyyyMMdd_HHmmss"
        let filename = "Recording_\(formatter.string(from: Date())).mov"
        let outputURL = FileManager.default.temporaryDirectory.appendingPathComponent(filename)
        movieOutput.startRecording(to: outputURL, recordingDelegate: self)
    }
    
    private func stopRecordingVideo() {
        if movieOutput.isRecording {
            recordingTimer?.invalidate()
            movieOutput.stopRecording()
        }
    }
    
    private func saveVideoToLibrary(url: URL) {
        PHPhotoLibrary.requestAuthorization { status in
            guard status == .authorized else { return }
            PHPhotoLibrary.shared().performChanges {
                PHAssetChangeRequest.creationRequestForAssetFromVideo(atFileURL: url)
            }
        }
    }
    
    func startSession() {
        sessionQueue.async {
            if !self.session.isRunning {
                self.session.startRunning()
            }
        }
    }
    func startHandDetection() {
        sessionQueue.async {
            self.isDetecting = true
        }
    }

    public func triggerCountdownAndCapture() {
        // For now, just capture photo directly (no countdown)
        capturePhoto()
    }
    
    public func stopTimerOrRecording() {
        if isRecording {
            stopRecordingVideo()
            isRecording = false
        } else {
            // No timer/recording to stop, do nothing or add more logic later if needed
        }
    }
    
    public func startTimer(total: Int = 3) {
        // Only set timerTotal and timerCount if timerPurpose is not nil or is already set for the same purpose
        // (To avoid overwriting timerPurpose if already set)
        if self.timerPurpose == nil || self.timerCount == 0 {
            self.timerTotal = total
            self.timerCount = total
        }

        print("‚ñ∂Ô∏è „Çø„Ç§„Éû„ÉºÈñãÂßã: ÂêàË®à \(total) Áßí")

        Timer.scheduledTimer(withTimeInterval: 1.0, repeats: true) { [weak self] timer in
            guard let self = self else {
                timer.invalidate()
                return
            }

            Task { @MainActor in
                if self.timerCount > 0 {
                    self.timerCount -= 1
                    print("‚è≥ „Çø„Ç§„Éû„ÉºÊõ¥Êñ∞: ÊÆã„Çä \(self.timerCount) Áßí")
                } else {
                    self.timerCount = 0
                    timer.invalidate()
                    print("‚èπÔ∏è „Çø„Ç§„Éû„ÉºÁµÇ‰∫Ü")
                }
            }
        }
    }
    
    public func stopTimer() {
        self.timerCount = 0
    }
    
    private func resetGestureState() {
        self.currentGesture = nil
        self.gestureStartTime = nil
        self.timerPurpose = nil
        self.timerCount = 0
        self.timerTotal = 0
        self.gestureLock = false
    }
}

extension CameraManager: AVCaptureFileOutputRecordingDelegate {
    func fileOutput(_ output: AVCaptureFileOutput, didFinishRecordingTo outputFileURL: URL, from connections: [AVCaptureConnection], error: Error?) {
        if let error = error {
            print("ÂãïÁîª‰øùÂ≠òÂ§±Êïó: \(error)")
            return
        }
        saveVideoToLibrary(url: outputFileURL)
    }
}

extension CameraManager: AVCaptureVideoDataOutputSampleBufferDelegate {
    func captureOutput(_ output: AVCaptureOutput, didOutput sampleBuffer: CMSampleBuffer, from connection: AVCaptureConnection) {
        guard isDetecting,
              let pixelBuffer = CMSampleBufferGetImageBuffer(sampleBuffer) else { return }

        let handler = VNImageRequestHandler(cvPixelBuffer: pixelBuffer, orientation: .up, options: [:])

        do {
            try handler.perform([handPoseRequest])
            guard let observation = handPoseRequest.results?.first else {
                // „Ç™„É¨„É≥„Ç∏ÔºàgestureHoldÔºù„Éî„Éº„ÇπÊ§úÁü•‰∏≠ÔºâÁä∂ÊÖã„Åß„Éî„Éº„Çπ„ÅåÊ§úÁü•„Åß„Åç„Å™„Åè„Å™„Å£„Åü„ÇâÂç≥Âàª‰∏≠Êñ≠„Åó„ÄÅ„Çø„Ç§„Éû„ÉºÈùûË°®Á§∫„Å´„Åô„Çã
                if self.timerPurpose == .gestureHold {
                    DispatchQueue.main.async {
                        self.timerPurpose = nil
                        self.resetGestureState()
                    }
                }
                return
            }

            if gestureLock {
                let recognizedPoints = try observation.recognizedPoints(.all)
                let thumbTip = recognizedPoints[.thumbTip]
                let indexTip = recognizedPoints[.indexTip]
                let middleTip = recognizedPoints[.middleTip]
                if let thumb = thumbTip, let index = indexTip, let middle = middleTip,
                   thumb.confidence > 0.3, index.confidence > 0.3, middle.confidence > 0.3 {
                    let distance = hypot(index.location.x - middle.location.x,
                                         index.location.y - middle.location.y)
                    let isFist = distance < 0.05
                    if !isFist { return }
                } else {
                    return
                }
            }

            let recognizedPoints = try observation.recognizedPoints(.all)

            // Simple heuristic for detecting hand openness (e.g., open palm vs closed fist)
            let thumbTip = recognizedPoints[.thumbTip]
            let indexTip = recognizedPoints[.indexTip]
            let middleTip = recognizedPoints[.middleTip]

            if let thumb = thumbTip, let index = indexTip, let middle = middleTip,
               thumb.confidence > 0.2, index.confidence > 0.2, middle.confidence > 0.2 {
                gestureFailureCount = 0  // reset failure count
            } else {
                gestureFailureCount += 1
                if gestureFailureCount >= maxGestureFailures {
                    DispatchQueue.main.async {
                        self.timerPurpose = nil
                        self.resetGestureState()
                    }
                }
                // „Åì„Åì„ÇÇgestureHold‰∏≠„Åß„ÅÇ„Çå„Å∞Âç≥‰∏≠Êñ≠
                if self.timerPurpose == .gestureHold {
                    DispatchQueue.main.async {
                        self.timerPurpose = nil
                        self.resetGestureState()
                    }
                }
                return
            }

            let distance = hypot(indexTip!.location.x - middleTip!.location.x,
                                 indexTip!.location.y - middleTip!.location.y)

            DispatchQueue.main.async {
                let gesture: String
                if distance < 0.05 {
                    gesture = "fist"
                } else {
                    let isPeace = abs(indexTip!.location.y - middleTip!.location.y) > 0.1
                    gesture = isPeace ? "peace" : "palm"
                }

                let now = Date()
                if self.currentGesture != gesture {
                    self.currentGesture = gesture
                    self.gestureStartTime = now
                } else if let start = self.gestureStartTime {
                    let elapsed = now.timeIntervalSince(start)

                    if elapsed >= 2.0 {
                        // Added: If timerPurpose == .captureDelay and gesture is fist, cancel timer and reset state immediately
                        if gesture == "fist" && self.timerPurpose == .captureDelay {
                            self.timerPurpose = nil
                            self.resetGestureState()
                            return
                        }

                        switch gesture {
                        case "fist":
                            // If timerPurpose is gestureHold or captureDelay, cancel immediately
                            if self.timerPurpose == .gestureHold || self.timerPurpose == .captureDelay {
                                self.timerPurpose = nil
                                self.resetGestureState()
                                return
                            }
                            print("‚úä „Ç∞„ÉºÊ§úÂá∫")
                            self.timerTotal = 0
                            self.timerCount = 0
                            self.stopRecordingVideo()
                            self.isRecording = false
                            self.resetGestureState()
                        case "peace":
                            print("‚úåÔ∏è „Éî„Éº„ÇπÊ§úÂá∫ÔºàÂÜôÁúüÊíÆÂΩ±Ôºâ")
                            self.timerPurpose = .gestureHold
                            self.startTimer(total: 2) // UIË°®Á§∫„ÅØ2Áßí„Å´Ë¶ã„Åõ„Çã
                            self.gestureLock = true
                            DispatchQueue.main.asyncAfter(deadline: .now() + 1.5) {
                                self.timerPurpose = .captureDelay
                                self.startTimer(total: 3) // for capture countdown
                                DispatchQueue.main.asyncAfter(deadline: .now() + 3.0) {
                                    self.capturePhoto()
                                    self.timerPurpose = nil
                                    self.timerCount = 0
                                    self.timerTotal = 0
                                    self.resetGestureState()
                                }
                            }
                        case "palm":
                            print("üñê „Éë„ÉºÊ§úÂá∫ÔºàÈå≤ÁîªÈñãÂßãÔºâ")
                            self.timerPurpose = .gestureHold
                            self.startTimer(total: 2) // UIË°®Á§∫„ÅØ2Áßí„Å´Ë¶ã„Åõ„Çã
                            self.gestureLock = true
                            DispatchQueue.main.asyncAfter(deadline: .now() + 1.5) {
                                self.timerPurpose = .captureDelay
                                self.startTimer(total: 3)
                                DispatchQueue.main.asyncAfter(deadline: .now() + 3.0) {
                                    self.startRecording(after: 0)
                                    self.timerPurpose = nil
                                    self.timerCount = 0
                                    self.timerTotal = 0
                                    self.resetGestureState()
                                }
                            }
                        default:
                            self.resetGestureState()
                            break
                        }
                    }
                }
            }
        } catch {
            print("‚ùå Vision error: \(error)")
        }
    }
}

// MARK: - AVCapturePhotoCaptureDelegate
extension CameraManager: AVCapturePhotoCaptureDelegate {
    func photoOutput(_ output: AVCapturePhotoOutput, didFinishProcessingPhoto photo: AVCapturePhoto, error: Error?) {
        guard let data = photo.fileDataRepresentation(),
              let image = UIImage(data: data) else { return }

        PHPhotoLibrary.requestAuthorization { status in
            guard status == .authorized || status == .limited else { return }
            PHPhotoLibrary.shared().performChanges({
                PHAssetChangeRequest.creationRequestForAsset(from: image)
            }, completionHandler: { success, error in
                if let error = error {
                    print("‚ùå ÂÜôÁúü‰øùÂ≠òÂ§±Êïó: \(error.localizedDescription)")
                } else {
                    print("‚úÖ ÂÜôÁúü„Çí‰øùÂ≠ò„Åó„Åæ„Åó„Åü")
                }
            })
        }
    }
}

// MARK: - Photo capture helpers
extension CameraManager {
    private func capturePhoto() {
        let settings = AVCapturePhotoSettings()
        photoOutput.capturePhoto(with: settings, delegate: self)
    }
}

